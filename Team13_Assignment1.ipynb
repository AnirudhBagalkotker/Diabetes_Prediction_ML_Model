{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj_r89FzT41w"
      },
      "source": [
        "# **BITS F464 - Semester 1 - MACHINE LEARNING**\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "**ASSIGNMENT 1 - LINEAR MODELS FOR REGRESSION AND CLASSIFICATION**\n",
        "--------------------------------------------------------------------------------\n",
        "***Team number: 13***\n",
        "\n",
        "---\n",
        "***Team Members: ANIRUDH BAGALKOTKER, KARTIK PANDEY, ADWAIT KULKARNI, JOY SINHA, PIYUSH JAJRA***\n",
        "\n",
        "---\n",
        "***IDs: 2021A7PS2682H, 2021A7PS2574H, 2021A7PS2995H, 2021A8PS1606H, 2021B4A72969H***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_duS0Zn17c3"
      },
      "source": [
        "This assignment aims to identify the differences between three sets of Machine Learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT-dTtra2h2n"
      },
      "source": [
        "# **_1. Dataset Generation_**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UsOVUj22wrz"
      },
      "source": [
        "You are given a sample Diabetes dataset. Using this, please develop your own dataset consisting of 500 records. You can use the given code to generate your own dataset. Submit the generated dataset as a .csv file along with your python notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8uONwSjNSc-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from sdv.datasets.local import load_csvs\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "from sdv.lite import SingleTablePreset\n",
        "import warnings\n",
        "warnings.filterwarnings( \"ignore\" )\n",
        "\n",
        "# Getting the current directory using os.path and loading the csv file with the sample diabetes dataset\n",
        "folderName = os.getcwd()\n",
        "datasets = load_csvs(folder_name=folderName)\n",
        "real_data = datasets[\"diabetes\"]\n",
        "\n",
        "# Generating metadata for the sample dataset\n",
        "metadata = SingleTableMetadata()\n",
        "metadata.detect_from_csv(filepath=folderName + \"/diabetes.csv\")\n",
        "\n",
        "# Visualizing the metadata and print it\n",
        "real_data.head()\n",
        "metadata.visualize()\n",
        "print(\"\\n\")\n",
        "print(metadata.to_dict())\n",
        "\n",
        "# Initializing a SingleTablePreset object with the metadata and fitting the synthesizer and sampling with the real_data input.\n",
        "synthesizer = SingleTablePreset(metadata, name=\"FAST_ML\")\n",
        "synthesizer.fit(data=real_data)\n",
        "\n",
        "# Generating 500 rows of synthetic data using the synthesizer and saving it as a csv and the synthesizer as a pkl\n",
        "rows = 500\n",
        "synthetic_data = synthesizer.sample(num_rows=rows)\n",
        "synthetic_data.to_csv(\"synthetic_diabetes.csv\", index=False)\n",
        "synthesizer.save(\"diabetes.pkl\")\n",
        "print(\"\\nSynthetic data generated.\\n\")\n",
        "print(synthetic_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDu7bwbNRhaK"
      },
      "source": [
        "# ***2. Preprocess and perform exploratory data analysis of the dataset obtained***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAd4cNwERr90"
      },
      "outputs": [],
      "source": [
        "from sdv.evaluation.single_table import evaluate_quality\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Preprocessing of the Synthetic Data\n",
        "\n",
        "# Handle missing values (if any) by replacing them with the mean\n",
        "synthetic_data.fillna(synthetic_data.mean(), inplace=True)\n",
        "\n",
        "print(\"\\nSynthetic data Preprocessed.\\n\")\n",
        "\n",
        "# Exploratory Data Analysis of the Synthetic Data\n",
        "print(\"\\nEDA for Synthetic data.\\n\")\n",
        "\n",
        "# Display the Outcomes and its mean\n",
        "print(synthetic_data['Outcome'].value_counts())\n",
        "print(\"\\n\")\n",
        "print(synthetic_data.groupby('Outcome').mean())\n",
        "print(\"\\n\")\n",
        "\n",
        "# Display basic statistics\n",
        "print(synthetic_data.describe())\n",
        "print(\"\\n\")\n",
        "\n",
        "# Check data types and missing values\n",
        "print(synthetic_data.info())\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate and visualize correlations between numeric columns using cluster maps and box plots using seaborn\n",
        "\n",
        "# Calculate correlations\n",
        "correlation_matrix = synthetic_data.corr()\n",
        "\n",
        "# Plot clustermap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.clustermap(correlation_matrix, cmap=\"RdBu\", center=0, cbar=True, annot=True)\n",
        "plt.title(\"Correlation Clustermap\")\n",
        "plt.show()\n",
        "\n",
        "# Box plot\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.boxplot(x=\"Outcome\", y=\"Glucose\", data=synthetic_data)\n",
        "plt.xlabel(\"Outcome\")\n",
        "plt.ylabel(\"Glucose\")\n",
        "plt.title(\"Box Plot of Glucose by Outcome\")\n",
        "plt.show()\n",
        "\n",
        "# Evaluating the quality of the synthetic data using sdv\n",
        "quality_report = evaluate_quality(real_data, synthetic_data, metadata)\n",
        "quality_report.get_visualization(\"Column Shapes\")\n",
        "\n",
        "# Save the Synthetic Data and the Synthesizing Model after preprocessing and evaluation\n",
        "synthetic_data.to_csv(\"synthetic_diabetes.csv\", index=False)\n",
        "synthesizer.save(\"diabetes.pkl\")\n",
        "\n",
        "# Separating the features and target\n",
        "target = synthetic_data[\"Outcome\"]\n",
        "features = synthetic_data.drop(columns=\"Outcome\", axis = 1)\n",
        "\n",
        "# Normalization and Standardization\n",
        "\n",
        "# Normalizing the data\n",
        "# features = (features - features.min()) / (features.max() - features.min())\n",
        "\n",
        "# Standardizing the data\n",
        "features = (features - features.mean()) / features.std()\n",
        "\n",
        "# Splitting the data into training (80%) and test (20%)\n",
        "total_samples = len(features)\n",
        "train_samples = int(0.8 * total_samples)\n",
        "\n",
        "# Shuffle the indices to randomize the data\n",
        "indices = np.arange(total_samples)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Split the indices into training and test sets\n",
        "train_indices = indices[:train_samples]\n",
        "test_indices = indices[train_samples:]\n",
        "\n",
        "# Create training and test data\n",
        "x_tr = features.iloc[train_indices]\n",
        "y_tr = target.iloc[train_indices]\n",
        "x_te = features.iloc[test_indices]\n",
        "y_te = target.iloc[test_indices]\n",
        "\n",
        "print(\"\\nx_tr:\\n\",x_tr.head())\n",
        "print(\"\\ny_tr:\\n\",y_tr.head())\n",
        "print(\"\\nx_te:\\n\",x_te.head())\n",
        "print(\"\\ny_te:\\n\",y_te.head())\n",
        "\n",
        "# Accuracy Score function\n",
        "def accuracy_score(y_pred, y_true):\n",
        "\t\"\"\"\n",
        "\tThe accuracy_score function takes in two arrays of labels and returns the fraction\n",
        "\tof time that they are equal. This is known as the accuracy score, or more commonly,\n",
        "\tthe classification rate. The function can also take an optional third parameter to specify \n",
        "\ta normalization method for when there are unequal numbers of predictions between classes.\n",
        "\n",
        "\t:param y_pred: Input the predicted values of y\n",
        "\t:param y_true: Pass in the actual labels of the data and y_pred is used to pass in our predicted labels\n",
        "\t:return: The fraction of correct predictions\n",
        "\t\"\"\"\n",
        "\n",
        "\tnum_correct = np.sum(y_true == y_pred)\n",
        "\tnum_total = len(y_true)\n",
        "\n",
        "\treturn num_correct / num_total\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y81SQxOrRso5"
      },
      "source": [
        "# ***3. Comparison of Stochastic Gradient Descent and Batch Gradient Descent using Linear Regression***\n",
        "\n",
        "## **_Stochastic Gradient Descent_**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQ8CVHsER-Mh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqIC34nWR-n7"
      },
      "source": [
        "## **_Batch Gradient Descent_**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hA5FysjSBzj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g7NxS5sSCRv"
      },
      "source": [
        "## **_Insights drawn (plots, markdown explanations)_**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pw63z3amSSo_"
      },
      "outputs": [],
      "source": [
        "#plot a graph using any python lib (matplotlib, plotly etc..)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- Explain your model Implementation using mathematical formulas and algorithms -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p-mPVFCSe9V"
      },
      "source": [
        "# **_4. Comparison of Lasso and Ridge Regression using Polynomial Regression_**\n",
        "\n",
        "## **_Lasso Regression_**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTjoKWdNSpcE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr-p_RtzSqUF"
      },
      "source": [
        "## **_Ridge Regression_**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWqMiCzVSuAD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlUMAWsiSug9"
      },
      "source": [
        "## **_Insights drawn (plots, markdown explanations)_**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRRNyaimS0iR"
      },
      "outputs": [],
      "source": [
        "#plot a graph using any python lib (matplotlib, plotly etc..)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- Explain your model Implementation using mathematical formulas and algorithms -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzSfpXtdS_q0"
      },
      "source": [
        "# **_5. Comparison of Logistic Regression and Least Squares Classification_**\n",
        "\n",
        "## **_Logistic Regression_**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLCup6QlTG0G"
      },
      "outputs": [],
      "source": [
        "class Logistic_Regression():\n",
        "\t\n",
        "\n",
        "\t# defining the constructor with learning rate and no of iterations (Hyperparameters)\n",
        "\tdef __init__(self, learning_rate, no_of_iterations):\n",
        "\t\t\"\"\"\n",
        "\t\tThe __init__ function is called when the class is instantiated.\n",
        "\t\tSets up the initial values of all attributes, and it can also do any other setup that might be necessary for \n",
        "\t\tyour object to function properly.\n",
        "\t\t\n",
        "\t\t:param self: Represent the instance of the class\n",
        "\t\t:param learning_rate: Control how much the weights are adjusted each time\n",
        "\t\t:param no_of_iterations: Set the number of iterations for which we want to run the gradient descent algorithm\n",
        "\t\t:return: Nothing\n",
        "\t\t\"\"\"\n",
        "        \n",
        "\t\tself.learning_rate = learning_rate\n",
        "\t\tself.no_of_iterations = no_of_iterations\n",
        "\n",
        "\n",
        "\n",
        "    # model function to train the model with dataset\n",
        "\tdef model(self, X, Y):\n",
        "\t\t\"\"\"\n",
        "\t\tThe model function is used to train the model.\n",
        "\t\tIt takes in two parameters: X and Y, which are numpy arrays/matrices of shape (m,n) and (m,1) respectively.\n",
        "\t\tThe function updates the weights w and bias b using gradient descent algorithm.\n",
        "\n",
        "\t\t:param self: Represent the instance of the class\n",
        "\t\t:param X: Store the training data\n",
        "\t\t:param Y: Calculate the error and the weights\n",
        "\t\t:return: Nothing\n",
        "\t\t\"\"\"\n",
        "\t\t# number of data points(rows) = m and no of features(columns) = n\n",
        "\t\tself.m, self.n = X.shape\n",
        "\n",
        "\t\t# initializing the weights and bias to zero\n",
        "\t\tself.w = np.zeros(self.n)\n",
        "\t\tself.b = 0\n",
        "\t\tself.X = X\n",
        "\t\tself.Y = Y\n",
        "\n",
        "\t\t# implementing gradient descent for optimization\n",
        "\t\tfor i in range(self.no_of_iterations):\n",
        "\t\t\tself.update_weights_and_bias()\n",
        "\n",
        "\n",
        "\t# function for updating the weights and bias using gradient descent\n",
        "\tdef update_weights_and_bias(self):\n",
        "\t\t\"\"\"\n",
        "\t\tThe update_weights_and_bias function updates the weights and bias using the gradient descent formula.\n",
        "\t\tThe function takes in no arguments, but uses self.w, self.b, self.X and self.Y to update \n",
        "\t\tthe weights and bias.\n",
        "\n",
        "\t\t:param self: Represent the instance of the class\n",
        "\t\t:return: The updated weights and bias\n",
        "\t\t\"\"\"\n",
        "\t\t# weights are updated using the formula w := w - learning_rate * dw\n",
        "\t\t# bias is updated using the formula b := b - learning_rate * db\n",
        "\n",
        "        # Y_hat formula (sigmoid function) = w.X + b\n",
        "\t\tY_hat = 1 / (1 + np.exp(-(self.X.dot(self.w) + self.b)))\n",
        "        \n",
        "        # derivatives\n",
        "\t\tdw = (1/self.m)*np.dot(self.X.T, (Y_hat - self.Y))\n",
        "\t\tdb = (1/self.m)*np.sum(Y_hat - self.Y)\n",
        "\n",
        "\t\t# updating the weights and bias using the gradient descent formula\n",
        "\t\tself.w = self.w - self.learning_rate * dw\n",
        "\t\tself.b = self.b - self.learning_rate * db\n",
        "\n",
        "\n",
        "\n",
        "\t# predict function to predict the output using Sigmoid Equation and Decision Boundary\n",
        "\tdef predict(self, X):\n",
        "\t\t\"\"\"\n",
        "\t\tThe predict function takes in a matrix of features and returns the predicted labels for each row.\n",
        "\t\tThe predict function uses the sigmoid function to calculate Y_hat, which is then used to determine if \n",
        "\t\tthe label should be 1 or 0. If Y_hat > 0.5, then it is classified as 1; otherwise it is classified as 0.\n",
        "\n",
        "\t\t:param self: Represent the instance of the class\n",
        "\t\t:param X: Pass the input data to the model\n",
        "\t\t:return: The predicted values of y (vector) for the given x\n",
        "\t\t\"\"\"\n",
        "\t\t# predicting the output by checking Y_hat > 0.5 for 1 and Y_hat <= 0.5 for 0\n",
        "\t\tY_pred = 1 / (1 + np.exp(-(X.dot(self.w) + self.b)))\n",
        "\t\tY_pred = np.where(Y_pred > 0.5, 1, 0)\n",
        "\t\treturn Y_pred\n",
        "\n",
        "# Training the model\n",
        "classifier = Logistic_Regression(learning_rate=0.01, no_of_iterations=1000)\n",
        "classifier.model(x_tr, y_tr)\n",
        "\n",
        "# Model Evaluation\n",
        "\n",
        "# Model Evaluation for Training Data\n",
        "x_train_predict = classifier.predict(x_tr)\n",
        "train_data_accuracy = accuracy_score(x_train_predict, y_tr)\n",
        "\n",
        "print(\"\\nThe Accuracy Score of Training Data: \", train_data_accuracy)\n",
        "\n",
        "# Model Evaluation for Test Data\n",
        "x_test_predict = classifier.predict(x_te)\n",
        "test_data_accuracy = accuracy_score(x_test_predict, y_te)\n",
        "\n",
        "print(\"\\nThe Accuracy Score of Test Data: \", test_data_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdX2kQ-nTHXc"
      },
      "source": [
        "## **_Least Squares Classification_**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7qJtwGnTMdb"
      },
      "outputs": [],
      "source": [
        "class LMSClassifier:\n",
        "    \n",
        "    # defining the constructor with learning rate and no of iterations (Hyperparameters)\n",
        "    def __init__(self, learning_rate, no_of_iterations):\n",
        "        \"\"\"\n",
        "\t\tThe __init__ function is called when the class is instantiated.\n",
        "\t\tSets up the initial values of all attributes, and it can also do any other setup that might be necessary for \n",
        "\t\tyour object to function properly.\n",
        "\t\t\n",
        "\t\t:param self: Represent the instance of the class\n",
        "\t\t:param learning_rate: Control how much the weights are adjusted each time\n",
        "\t\t:param no_of_iterations: Set the number of iterations for which we want to run the gradient descent algorithm\n",
        "\t\t:return: Nothing\n",
        "\t\t\"\"\"\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.no_of_iterations = no_of_iterations\n",
        "\n",
        "    # model function to train the model with dataset\n",
        "    def model(self, X, Y):\n",
        "        \"\"\"\n",
        "\t\tThe model function is used to train the model.\n",
        "\t\tIt takes in two parameters: X and Y, which are numpy arrays/matrices of shape (m,n) and (m,1) respectively.\n",
        "\t\tThe function updates the weights w and bias b using gradient descent algorithm.\n",
        "\n",
        "\t\t:param self: Represent the instance of the class\n",
        "\t\t:param X: Store the training data\n",
        "\t\t:param Y: Calculate the error and the weights\n",
        "\t\t:return: Nothing\n",
        "\t\t\"\"\"\n",
        "        \n",
        "        no_samples, no_features = X.shape\n",
        "        X = X.to_numpy()\n",
        "        Y = Y.to_numpy()\n",
        "        \n",
        "        # Initializing array of ones\n",
        "        X1 = np.ones(no_samples)\n",
        "        X1 = X1.reshape(1,400)\n",
        "        \n",
        "        # Transform and concatenate columns of the input array X into the new array X1\n",
        "        for j in range(no_features):\n",
        "            x_i = X[:, j].reshape(-1, 1)\n",
        "            x_i = x_i.T\n",
        "            X1 = np.concatenate((X1, x_i), axis=0)\n",
        "        \n",
        "        Y = Y.reshape(-1, 1)\n",
        "        X1 = X1.T\n",
        "        \n",
        "        # Compute the coefficients (beta) for linear regression using the pseudo-inverse method\n",
        "        self.beta = np.linalg.pinv(X1.T @ X1) @ (X1.T @ Y)\n",
        "\n",
        "    # predict function to predict the output using the coefficients (beta)\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"\n",
        "        The predict function takes in a matrix of test data and returns the predicted values for each sample.\n",
        "        The function first adds a column of ones to the test data, then multiplies it by beta to get Y_hat.\n",
        "        It then reshapes Y_hat into an array with one row and no_samples columns, which is used to calculate mean. \n",
        "        Then it loops through all elements in Y_hat and sets them equal to 0 if they are less than mean or 1 otherwise.\n",
        "        \n",
        "        :param self: Represent the instance of the class\n",
        "        :param X_test: Pass the test data to the predict function\n",
        "        :return: A vector of predictions Y_pred given X\n",
        "        \"\"\"\n",
        "        \n",
        "        no_samples, no_features = X_test.shape\n",
        "        X = np.concatenate((np.ones((no_samples, 1)), X_test), axis=1)\n",
        "        Y_hat = X @ self.beta\n",
        "        \n",
        "        # Calculate mean of Y_hat\n",
        "        Y_hat = Y_hat.reshape(no_samples, )\n",
        "        mean = np.mean(Y_hat)\n",
        "        Y_hat = Y_hat.reshape(1, no_samples)\n",
        "        \n",
        "\t\t# predicting the output by checking Y_hat > mean for 1 and Y_hat <= mean for 0\n",
        "        for j in range(no_samples):\n",
        "            if Y_hat[0, j] > mean:\n",
        "                Y_hat[0, j] = 1\n",
        "            else:\n",
        "                Y_hat[0, j] = 0\n",
        "        Y_pred = Y_hat.reshape(no_samples, )\n",
        "        return Y_pred\n",
        "\n",
        "# Training the model\n",
        "classifier = LMSClassifier(learning_rate=0.01, no_of_iterations=1000)\n",
        "classifier.model(x_tr, y_tr)\n",
        "classifier.beta\n",
        "\n",
        "# Model Evaluation for Training Data\n",
        "x_train_predict = classifier.predict(x_tr)\n",
        "train_data_accuracy = accuracy_score(x_train_predict, y_tr)\n",
        "\n",
        "print(\"\\nThe Accuracy Score of Training Data: \", train_data_accuracy)\n",
        "\n",
        "# Model Evaluation for Test Data\n",
        "x_test_predict = classifier.predict(x_te)\n",
        "test_data_accuracy = accuracy_score(x_test_predict, y_te)\n",
        "\n",
        "print(\"\\nThe Accuracy Score of Training Data: \", test_data_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSoa7KO1TM6-"
      },
      "source": [
        "## **_Insights drawn (plots, markdown explanations)_**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KYE7sstTW4D"
      },
      "outputs": [],
      "source": [
        "#plot a graph using any python lib (matplotlib, plotly etc..)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- Explain your model Implementation using mathematical formulas and algorithms -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81SwQ_y4TaSc"
      },
      "source": [
        "# **_5. References_**\n",
        "\n",
        "1.   SDV: https://docs.sdv.dev/sdv/\n",
        "2.   Preprocessing: https://towardsdatascience.com/data-preprocessing-and-eda-for-data-science-50ba6ea65c0a\n",
        "3.   Preprocessing for Missing Data using Pandas: https://pandas.pydata.org/docs/user_guide/missing_data.html\n",
        "4.   EDA using Seaborn: https://www.analyticsvidhya.com/blog/2021/08/how-to-perform-exploratory-data-analysis-a-guide-for-beginners/\n",
        "5.   Plotting Graphs using Seaborn: https://seaborn.pydata.org/\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
